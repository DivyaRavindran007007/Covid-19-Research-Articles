{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CORD 19  - Group 4\n",
    "* For this project we have metadata, pdf_json and pmc_json file\n",
    "* We need to combine json file into one csv with reference of metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/scratch/midway2/reshmask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project2/msca/ivy2/software2/install/Anaconda3-2019.10/envs/ML1/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,4,5,6,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "metadata  = pd.read_csv(root_path+'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata['cord_uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = root_path+'document_parses/'\n",
    "pdf_json     = glob.glob(f'{path_to_json}/pdf_json/*.json', recursive=True)\n",
    "pmc_json     = glob.glob(f'{path_to_json}/pmc_json/*.json', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata.columns\n",
    "# test = pdf_json[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing abstracts: 58970\n",
      "% of missing abstracts: 28.790711980588117\n"
     ]
    }
   ],
   "source": [
    "#number of null abstracts\n",
    "print ('Number of missing abstracts:', metadata[pd.isnull(metadata['abstract'])].shape[0])\n",
    "print ('% of missing abstracts:', (metadata[pd.isnull(metadata['abstract'])].shape[0]/metadata.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pdf and pmc concerns - if you have pdf then you don't need to worry about PMC json files\n",
    "\n",
    "Whenever pdf json is null - we will not have body_text of a paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing pdf json (body_text): 119577\n",
      "% of missing pdf json (body_text): 58.38065061052714\n"
     ]
    }
   ],
   "source": [
    "## Assumption that every pdf json file has body_text - we should atleast get\n",
    "print ('Number of missing pdf json (body_text):', metadata[pd.isnull(metadata['pdf_json_files'])].shape[0])\n",
    "print ('% of missing pdf json (body_text):', (metadata[pd.isnull(metadata['pdf_json_files'])].shape[0]/metadata.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pdf = metadata[pd.notnull(metadata['pdf_json_files'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing pmc json: 138831\n",
      "% of missing pmc json: 67.78096209898303\n",
      "% of pmc json available when pdf json is missing: 1.9284943585437184\n"
     ]
    }
   ],
   "source": [
    "## Assumption that every pdf json file has body_text - we should atleast get\n",
    "print ('Number of missing pmc json:', metadata[pd.isnull(metadata['pmc_json_files'])].shape[0])\n",
    "print ('% of missing pmc json:', (metadata[pd.isnull(metadata['pmc_json_files'])].shape[0]/metadata.shape[0])*100)\n",
    "pmc_not_pdf = metadata[(pd.isnull(metadata['pdf_json_files'])) & (pd.notnull(metadata['pmc_json_files']))].shape[0]\n",
    "print ('% of pmc json available when pdf json is missing:', (pmc_not_pdf/metadata.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pmc_not_pdf = metadata[(pd.isnull(metadata['pdf_json_files'])) & (pd.notnull(metadata['pmc_json_files']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between pdf json and pmc json folder files with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sha_pdf = [name.replace('/scratch/midway2/reshmask/document_parses//pdf_json/', '').replace('.json', '') for name in pdf_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pdf json files: 90361\n",
      "% of pdf json available in metadata: 89.38369429289185\n"
     ]
    }
   ],
   "source": [
    "print ('Total pdf json files:', len(sha_pdf))\n",
    "inter_pdf = list(set(sha_pdf).intersection(set(metadata['sha'].values)))\n",
    "print ('% of pdf json available in metadata:',(len(inter_pdf)/len(sha_pdf))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pmc = [name.replace('/scratch/midway2/reshmask/document_parses//pmc_json/', '').replace('.xml.json', '') for name in pmc_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pmc json files: 65992\n",
      "pmc json is available where pdf is null when match in metadata: 3950\n",
      "% of pmc json available where pdf is null when match in metadata: 5.985574008970785\n"
     ]
    }
   ],
   "source": [
    "print ('Total pmc json files:', len(id_pmc))\n",
    "inter_pmc = list(set(id_pmc).intersection(set(metadata_pmc_not_pdf['pmcid'].values)))\n",
    "print ('pmc json is available where pdf is null when match in metadata:',len(inter_pmc))\n",
    "print ('% of pmc json available where pdf is null when match in metadata:',(len(inter_pmc)/len(id_pmc))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get body text along with abstract\n",
    "   * intersection pdf json files - only pdf json files which is available in metadata_pdf\n",
    "   * pmc json while where pdf is null & pmc json files which is available in metadata_pmc_not_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_body_pdf = getALLdataFrame(inter_pdf, metadata_pdf,'pdf', '/scratch/midway2/reshmask/document_parses//pdf_json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract_body_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_body_pmc = getALLdataFrame(inter_pmc, metadata, 'pmc', '/scratch/midway2/reshmask/document_parses//pmc_json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract_body_pmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Plan\n",
    "\n",
    "## Logic 1 = studying only body text\n",
    "    * data set 1 -  when you have abstract & body_text == logic 1\n",
    "    * data set 2 -  when you have only body text, no abstract == logic 1\n",
    "    * body_text_abstract = data set 1 + data set 2\n",
    "\n",
    "## Logic2 = studying only abstract\n",
    "    * data set 3 -  when you have only abstract, no body_text == logic 2\n",
    "    * abstract_only = data set 3\n",
    "\n",
    "## Discard papers where both body text and abstract are missing\n",
    "\n",
    "### descriptive analysis - combine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for logic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_body_scrp = pd.concat([abstract_body_pdf, abstract_body_pmc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_body_scrp['abstract'] = abstract_body_scrp['abstract'].apply(lambda x : np.nan if x is '' else x)\n",
    "abstract_body_scrp['body_text'] = abstract_body_scrp['body_text'].apply(lambda x : np.nan if x is '' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_body =  abstract_body_scrp[(pd.notnull(abstract_body_scrp['body_text'])) | (pd.notnull(abstract_body_scrp['abstract']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get missing abstracts which is not in pdfs, pmcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project2/msca/ivy2/software2/install/Anaconda3-2019.10/envs/ML1/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "metadata_abstract = metadata[pd.notnull(metadata['abstract'])]\n",
    "metadata_abstract['is_sha'] = metadata_abstract['sha'].apply(lambda x :  1 if x in inter_pdf else 0)\n",
    "metadata_abstract = metadata_abstract[metadata_abstract['is_sha'] ==0]\n",
    "metadata_abstract['is_pmc'] = metadata_abstract['pmcid'].apply(lambda x :  1 if x in inter_pmc else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_abstract = metadata_abstract[metadata_abstract['is_pmc'] ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_cols = ['paper_id', 'doi', 'abstract', 'body_text', 'authors', 'title', 'journal', 'publish_time', 'url', 'source_x']\n",
    "sel_cols = ['cord_uid', 'paper_id', 'doi', 'abstract', 'body_text',  'authors', 'title', 'journal', 'publish_time', 'url', 'source_x', 'institution', 'settlement', 'region', 'country']\n",
    "metadata_abstract.rename(columns={'sha': 'paper_id'}, inplace=True)\n",
    "metadata_abstract['paper_id'] = metadata_abstract[['paper_id', 'pmcid']].apply(lambda x : x['pmcid'] if pd.isnull(x['paper_id']) else x['paper_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_abstract['body_text']   = np.nan\n",
    "metadata_abstract['institution'] = np.nan\n",
    "metadata_abstract['settlement']  = np.nan\n",
    "metadata_abstract['region']      = np.nan\n",
    "metadata_abstract['country']     = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_abstract_sel = metadata_abstract[sel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77827, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_abstract_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([abstract_body, metadata_abstract_sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162545, 15)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_data.columns:\n",
    "    all_data[col] = all_data[col].apply(lambda x : x.replace(',', ' ') if pd.notnull(x) else x)\n",
    "    all_data[col] = all_data[col].apply(lambda x : x.replace('\\n', ' ') if pd.notnull(x) else x)\n",
    "    all_data[col] = all_data[col].apply(lambda x : x.replace('$', ' ') if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('cord19_V2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "ml1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
